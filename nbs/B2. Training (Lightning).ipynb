{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e79ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from fastprogress import progress_bar, master_bar\n",
    "import fastprogress\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "import IPython\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.profiler import record_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232153f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import lightning.pytorch as pl\n",
    "import math\n",
    "\n",
    "class TrainingTask(pl.LightningModule):\n",
    "    def __init__(self, model, model_hparams=None):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model_hparams = model_hparams\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Initialize AdamW optimizer\"\"\"\n",
    "        all_params = set(model.parameters())\n",
    "        customized_params = set()\n",
    "        groups = []\n",
    "        group_map = {}\n",
    "        for name,m in model.named_modules():\n",
    "            if hasattr(m, 'no_weight_decay') or hasattr(m, 'lr_scale'):\n",
    "                customized_params |= set(m.parameters())\n",
    "                m_wd = 0 if hasattr(m, 'no_weight_decay') else weight_decay\n",
    "                m_lr = lr * getattr(m, 'lr_scale', 1)\n",
    "                group = group_map.get((m_wd, m_lr), None)\n",
    "                if not group:\n",
    "                    group = {\"params\": [], \"names\": [], \"weight_decay\": m_wd, \"lr\": m_lr}\n",
    "                    groups.append(group)\n",
    "                    group_map[(m_wd, m_lr)] = group\n",
    "                group['params'] += m.parameters()\n",
    "                group['names'].append(name)\n",
    "                \n",
    "        other_params = all_params - customized_params\n",
    "        \n",
    "        param_groups = groups + [\n",
    "            {\"names\": [\"other\"], \"params\": list(other_params), \"weight_decay\": weight_decay },\n",
    "        ]\n",
    "\n",
    "        optimizer = torch.optim.AdamW(lr=self.model_hparams['lr0'], betas=(0.9, 0.95),\n",
    "                                      fused=True, params=param_groups)\n",
    "        \n",
    "        # modified from https://github.com/Lightning-AI/lightning/issues/5449#issuecomment-1501597319\n",
    "        def num_steps_per_epoch() -> int:\n",
    "            \"\"\"Get number of steps\"\"\"\n",
    "            # Accessing _data_source is flaky and might break\n",
    "            dataset = self.trainer.fit_loop._data_source.dataloader()\n",
    "            dataset_size = len(dataset)\n",
    "            num_devices = max(1, self.trainer.num_devices)\n",
    "            # math.ceil so always overestimate (underestimating throws exceptions)\n",
    "            num_steps = math.ceil(dataset_size / (self.trainer.accumulate_grad_batches * num_devices))\n",
    "            return num_steps\n",
    "        \n",
    "        total_steps = self.model_hparams['epochs'] * num_steps_per_epoch()\n",
    "        self.model_hparams['pct_start'] = min(0.3, self.model_hparams['warmup_steps'] / total_steps)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            pct_start=self.model_hparams['pct_start'],\n",
    "            max_lr=self.model_hparams['lr0'],\n",
    "            steps_per_epoch=num_steps_per_epoch(),\n",
    "            epochs=self.model_hparams['epochs'],\n",
    "            final_div_factor=25\n",
    "        )\n",
    "\n",
    "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        train_logits, train_loss = self.model.forward(*train_batch)\n",
    "\n",
    "        self.log(\"train_loss\", train_loss, sync_dist=True)\n",
    "        return train_loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        val_logits, val_loss = self.model.forward(*val_batch)\n",
    "\n",
    "        logs = dict(val_loss = val_loss)\n",
    "        if hasattr(self.model, 'val_true'):\n",
    "            for i,acc in enumerate((self.model.val_true / self.model.val_total).cpu().numpy()):\n",
    "                logs[f'acc/acc_{i}'] = acc\n",
    "            for i,pacc in enumerate((self.model.pval_true / self.model.pval_total).cpu().numpy()):\n",
    "                logs[f'acc/pacc_{i}'] = pacc\n",
    "        \n",
    "        self.log_dict(logs, sync_dist=True)\n",
    "        return val_loss\n",
    "    \n",
    "    def test_step(self, val_batch, batch_idx):\n",
    "        test_logits, test_loss = self.model.forward(*val_batch)\n",
    "\n",
    "        self.log(\"test_loss\", test_loss, sync_dist=True)\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae232d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from fastcore.script import anno_parser\n",
    "import shlex\n",
    "\n",
    "# watch out: we can only pass Python values as keyword arguments (not positional)\n",
    "# everything else has to be a string\n",
    "def parse_and_call(name, fun, args, kwargs={}, log_to_wandb=True):\n",
    "    p = anno_parser(fun)\n",
    "    args = p.parse_args(args).__dict__\n",
    "    args.pop('xtra'); args.pop('pdb')\n",
    "    if log_to_wandb and type(wandb_logger.experiment.config) == wandb.sdk.wandb_config.Config:\n",
    "        wandb_logger.experiment.config[name] = {k:v for k,v in args.items()}\n",
    "    args.update({k:v for k, v in kwargs.items()})\n",
    "    return fun(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 4\n"
     ]
    }
   ],
   "source": [
    "def test_fun(a:str=None, to:int = 2):\n",
    "    assert(a is not None)\n",
    "    print(a, to)\n",
    "parse_and_call(\"test\", test_fun, [\"--to\", \"4\"], dict(a=[]), log_to_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd039c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwe 2\n"
     ]
    }
   ],
   "source": [
    "def test_fun2(a:str, to:int = 2):\n",
    "    assert(a is not None)\n",
    "    print(a, to)\n",
    "\n",
    "parse_and_call(\"test\", test_fun2, [\"qwe\"], log_to_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--task', type=str, help='Task to train')\n",
    "parser.add_argument('--seed', type=int, default=0, help='Global training seed')\n",
    "parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')\n",
    "parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')\n",
    "parser.add_argument('--input-dir', type=str, default='', help='input data path') # fixed in the model for now\n",
    "parser.add_argument(\"--checkpoint-dir\", type=str, default=\"./checkpoints/\", help=\"directory to save the checkpoints\")\n",
    "parser.add_argument('--epochs', type=int, default=10, help='total training epochs')\n",
    "parser.add_argument('--validations_per_epoch', type=int, default=10, help='how many times to run validation during an epoch')\n",
    "parser.add_argument('--weight-decay', type=float, default=1e-2, help='optimizer weight decay')\n",
    "parser.add_argument('--lr0', type=float, default=1e-4, help='optimizer initial learning rate')\n",
    "parser.add_argument('--clip-gradient-norm', type=float, default=None, help='enable gradient norm clipping')\n",
    "parser.add_argument('--accumulate-grad-batches', type=int, default=1, help='perform the optimizer step only after going through several batches of samples')\n",
    "parser.add_argument('--warmup-steps', type=int, default=10000, help='total number steps during which the learning rate rises (defaults to 10k updates)')\n",
    "\n",
    "args = parser.parse_args().__dict__\n",
    "\n",
    "task_args: list = shlex.split(args.pop(\"task\"))\n",
    "task_name, task_args = task_args[0], task_args[1:]\n",
    "input_args: list = shlex.split(args.pop(\"input_dir\"))\n",
    "checkpoint_dir: str = args.pop(\"checkpoint_dir\")\n",
    "num_workers: int = args.pop(\"workers\")\n",
    "batch_size: int = args.pop(\"batch_size\")\n",
    "epochs: int = args.pop(\"epochs\")\n",
    "validations_per_epoch: int = args.pop(\"validations_per_epoch\")\n",
    "\n",
    "hyp_params = {}\n",
    "hyp_params['warmup_steps'] = args['warmup_steps']\n",
    "hyp_params['weight_decay'] = args['weight_decay']\n",
    "hyp_params['clip_gradient_norm'] = args['clip_gradient_norm']\n",
    "hyp_params['accumulate_grad_batches'] = args['accumulate_grad_batches']\n",
    "hyp_params['lr0'] = args['lr0']\n",
    "hyp_params['epochs'] = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "import importlib\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "wandb_logger = WandbLogger(project=f\"SpearTTS-{task_name}\")\n",
    "\n",
    "ckpt_callback = pl.callbacks.ModelCheckpoint(\n",
    "     dirpath=f'{task_name}-{epochs}e',\n",
    "     filename=task_name+\"-{epoch}-{step}-{val_loss:.2f}\",\n",
    "     monitor=\"val_loss\",\n",
    "     save_top_k=4,\n",
    "     every_n_epochs=1,\n",
    " )\n",
    "\n",
    "lr_monitor_callback = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "task = importlib.import_module(\"spear_tts_pytorch.\"+task_name)\n",
    "\n",
    "train_ds, val_ds = parse_and_call('dataset', task.load_datasets, input_args)\n",
    "\n",
    "val_loader = DataLoader(val_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    "    pin_memory=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "model = parse_and_call('model', task.make_model, task_args, dict(dataset=train_ds))\n",
    "\n",
    "task = TrainingTask(model, model_hparams=hyp_params)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=hyp_params['epochs'],\n",
    "                  accelerator=\"gpu\",\n",
    "                  profiler=\"simple\",\n",
    "                  precision='16-mixed',\n",
    "                  gradient_clip_val=hyp_params['clip_gradient_norm'],\n",
    "                  accumulate_grad_batches=hyp_params['accumulate_grad_batches'],\n",
    "                  val_check_interval=1/validations_per_epoch,\n",
    "                  enable_checkpointing=True,\n",
    "                  logger=wandb_logger,\n",
    "                  callbacks=[ckpt_callback, lr_monitor_callback])\n",
    "\n",
    "if type(wandb_logger.experiment.config) == wandb.sdk.wandb_config.Config:\n",
    "    wandb_logger.experiment.config.update(hyp_params)\n",
    "\n",
    "trainer.fit(model=task, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00406652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffffe92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
